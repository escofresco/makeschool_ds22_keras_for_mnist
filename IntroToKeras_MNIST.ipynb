{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "IntroToKeras-MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/escofresco/makeschool_ds22_keras_for_mnist/blob/main/IntroToKeras_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD9Dc4IUpfP2"
      },
      "source": [
        "# Introduction to Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_xAxRkSpfQB"
      },
      "source": [
        "In this notebook, we'll explore the Keras and use it to create a classifier to predict hand written digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vkmXwbGpfQJ"
      },
      "source": [
        "## Introduction and Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm7PsaTdpfQR"
      },
      "source": [
        "### What is Keras? Why use it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBzh8RuOpfQX"
      },
      "source": [
        "Keras is a high-level deep learning API that serves to build, train, evaluate, and as a toolbox to neural networks. This means that Keras is used to do deep learning by being a wrapper to more complex and low-level deep learning frameworks like TensorFlow, CNTK, and Theano. The same functions for Keras wrapped CNTK are the same for Keras wrapped Theano and TensorFlow. TensorFlow (TF), the current most popular deep learning library and open sourced by Google, has recently integrated it's framework with Keras, so now Keras comes in with TF. \n",
        "\n",
        "Well, that's all find and dandy, but why should we use Keras? What's wrong with using TF? And why is TF integrating Keras? What does this all mean? TF, as well as other deep learning libraries, can be a bit more complicated to use (for the exception of PyTorch, more on that in a second). As you may have already experienced, deep learning can be quite complex, having a *deep* understanding (pun intended) of everything that's going on is sometimes needed, making TF (pre-Keras integration) unfriendly. With the latest version of Keras, TF is now super easy to use. Since TF is the most common library, there are tons of add ons and pipelines for mobile and websites already made. Therefore, Keras/TF is ideal for the more common programmer.\n",
        "\n",
        "Are there other options? The other up-and-coming library is PyTorch, created by Facebook. PyTorch is more common in research circles (whereas Keras/TF is more common in industry) however the interface at a high level tends to be the same. Arguably, transitioning from Keras to PyTorch should be simple.\n",
        "\n",
        "So am I going to be using Keras or TF in this class? Both! In our case, they're the same thing. Again, Keras has been integrated by default to TF, Keras is a wrapper to TF. If you're going to be doing high level work (which will be 95% of the time), you're going to be calling and using Keras. If you're going into the nitty gritty low-level work of Neural Networks (i.e. creating your own custom loss function, activation function, or metrics), you're going to be using TF. If someone asks what deep learning framework you used in this class, TensorFlow! But do give a shoutout to Keras if you use `tf.keras` often.\n",
        "\n",
        "So for the rest of this notebook, we'll be using Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsIYyQpLpfQa"
      },
      "source": [
        "### Training Deep Learning Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BHup7bIpfQd"
      },
      "source": [
        "Neural nets can take a while to train; you may have heard this prior in the mystery of deep learning. So can your computer train neural networks? It depends. If you're doing **deep** deep learning, using +30 layers or working with an enormous amount of data, training could take forever. One would need a GPU on their computer. More than often, we use some sort of cloud computing, why Colab would be ideal. For more intensive trainings (since Colab shuts down after +12 hours), usually a cloud provider like AWS (Amazon) or GCP (Google) would be used.\n",
        "\n",
        "Keras/TF works with and without a GPU, but by default is set to without a GPU. In this notebook, we won't be working with intense computation, so a GPU isn't necessarily. However that doesn't mean that training can't take a while. If you're working on Colab, changing the computation setting from CPU to GPU may speed things up. Your decision on what to do.\n",
        "\n",
        "If you have a GPU on your computer, there are guides towards setting up TF with a GPU with certain requirements. Slack me (Kevin Marroquin) for more details since this installation can get tricky."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwh4Gz29pfQg"
      },
      "source": [
        "## Running an example: MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keZ_Rh0ppfQn"
      },
      "source": [
        "### Installing Tensorflow and Loading Imports\n",
        "\n",
        "First, we're going to install Keras, in case you're using this on your local computer. However, this should work under Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmcCSfQPpfQp"
      },
      "source": [
        "#See installation details here: https://www.tensorflow.org/install/\n",
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:24:47.193454Z",
          "start_time": "2020-11-05T10:24:47.145457Z"
        },
        "id": "qts6RxbwpfQ2"
      },
      "source": [
        "#Importing Keras and other imports\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C7lUeAipfRD"
      },
      "source": [
        "We're going to want reproducible results, so pre-defining random seeds is necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoKx3MJepfRG"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "#If the two lines above give you error, mute them and run the following:\n",
        "# import tensorflow\n",
        "# tensorflow.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj-oP-jBrT8v"
      },
      "source": [
        "Normally one wouldn't want to have a pre-defined random seed (in fact you would want the exact opposite), but in our case, since we want to be able to produce reprodicible results for grading purposes, it's needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP-A1vLUpfRQ"
      },
      "source": [
        "### Loading, Analyzing, and Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljYxYodspfRR"
      },
      "source": [
        "For this example, we will be using the [MNIST dataset](https://www.tensorflow.org/datasets/catalog/mnist). MNIST is a dataset of handwritten digits created to classify what type of digit, from zero to nine, is shown. MNIST is modified and, to some extent, normalized such that they're all the same size. Let's explore and see what kind of information MNIST have. If you've seen MNIST, this will probably be stuff you've seen before, so feel free to skip to the neural network part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T08:18:06.974049Z",
          "start_time": "2020-11-05T08:18:06.368984Z"
        },
        "id": "HTqQEvaPpfRV"
      },
      "source": [
        "#Loading datasets\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T08:19:47.487213Z",
          "start_time": "2020-11-05T08:19:47.478418Z"
        },
        "id": "0dDGrf_1pfRi"
      },
      "source": [
        "#Seeing shapes of data\n",
        "print(\"X_train:\", X_train_full.shape)\n",
        "print(\"y_train:\", y_train_full.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUH_dvUCpfRp"
      },
      "source": [
        "So we see that we have 60000 training datapoints and 10000 test. How does one of these datapoints look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T08:21:22.410866Z",
          "start_time": "2020-11-05T08:21:22.403207Z"
        },
        "id": "pOb2KNTApfRq"
      },
      "source": [
        "X_train_full"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T09:02:24.980655Z",
          "start_time": "2020-11-05T09:02:24.971846Z"
        },
        "id": "k5_ccoedpfRx"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T08:21:11.392618Z",
          "start_time": "2020-11-05T08:21:11.377924Z"
        },
        "id": "XAlok2nypfR6"
      },
      "source": [
        "X_train_full[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvxxZEhGpfSC"
      },
      "source": [
        "So an image is represented as a 28x28 image in pixels and it. It's a picture in black and white, representing pixel intensity from 0 to 255, where a 255 representing black and 0 representing white. Let's plot this to see the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T09:06:21.409749Z",
          "start_time": "2020-11-05T09:06:21.404006Z"
        },
        "id": "3lYMxiXhpfSK"
      },
      "source": [
        "#Looking at test data\n",
        "y_train_full"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T09:06:59.000370Z",
          "start_time": "2020-11-05T09:06:58.904785Z"
        },
        "id": "co2Xx8_2pfSU"
      },
      "source": [
        "#Rerun to get different numbers\n",
        "def plotImage(image):\n",
        "    \"\"\"A 28x28 array that represents an image.\"\"\"\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image, cmap=\"gray\")\n",
        "    plt.axis(False)\n",
        "    plt.show()\n",
        "sample_image = np.random.randint(0, len(X_train_full))\n",
        "print(\"The expected value is:\", y_train_full[sample_image])\n",
        "plotImage(X_train_full[sample_image])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO0SFGLBpfSa"
      },
      "source": [
        "Before using this data, we must preprocess it to our likings. Something that should be done before plugging our data into our neural net is to normalize and shift it for better results ([see more details here](https://stackoverflow.com/questions/4674623/why-do-we-have-to-normalize-the-input-for-an-artificial-neural-network)). If you want some quick intuition about our activation functions, or a sigmoid function, most of it's \"function\" (the part that's interesting and not a flat line) is near `x` = 0 than at `x` = 255, `X_train_full`'s max point. Normalizing and shifting our data brings it to the action of the function (seriously, no pun intended on this one) where the model may perform better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T08:49:46.967113Z",
          "start_time": "2020-11-05T08:49:46.748334Z"
        },
        "id": "__7J22nPpfSb"
      },
      "source": [
        "#Example of Sigmoid function\n",
        "def sigmoid(x):\n",
        "    return 1/(np.exp(-x) + 1)\n",
        "plt.plot(np.arange(-15, 15), sigmoid(np.arange(-15, 15)))\n",
        "plt.title(\"Sigmoid Function\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPj2cGySpfSk"
      },
      "source": [
        "Let's convert this data to 0 and 1, where 1 is the max pixel intensity (255) and zero is still zero. Anything in between is the scaled value of the original data. In the process, we will create a validation pair (of X and y) to test our model after training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T09:02:05.560541Z",
          "start_time": "2020-11-05T09:02:04.899064Z"
        },
        "id": "mlnrzkO6pfSl"
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255, X_train_full[5000:] / 255\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255\n",
        "#No need to do y_test since it's not being fed into the data.\n",
        "#Also, data is already shuffled, so no need to do so here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T09:09:23.480303Z",
          "start_time": "2020-11-05T09:09:23.474355Z"
        },
        "id": "TVy8woTjpfSq"
      },
      "source": [
        "Lastly, inputting a 2D datapoint into a neural network is a bit of work to implement and architect. To avoid harder work, we will transform our data into a 1D array. We will do this in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpXfBxChpfSr"
      },
      "source": [
        "### Creating A Simple Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umiVwSNUpfSs"
      },
      "source": [
        "Let's build a basic 2-layered neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T09:43:56.369221Z",
          "start_time": "2020-11-05T09:43:56.319699Z"
        },
        "id": "lfO8CDF4pfSt"
      },
      "source": [
        "#Including random seeds here again in case for reproducibility\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "#If the two lines above give you error, mute them and run the following:\n",
        "# import tensorflow\n",
        "# tensorflow.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"sigmoid\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"sigmoid\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "#Another similar way of writing the above code is:\n",
        "# model = keras.model.Sequential([\n",
        "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
        "#     keras.layers.Dense(300, activation=\"sigmoid\"),\n",
        "#     keras.layers.Dense(100, activation=\"sigmoid\"),\n",
        "#     keras.layers.Dense(10, activation=\"softmax\")\n",
        "# ])\n",
        "#Your choice in preference."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzoCOt6DpfSz"
      },
      "source": [
        "Going through the above code line by line:\n",
        "- The first line creates the simplest model composed of a single stack of layers connected sequentially. Needed in most cases to initialize the model.\n",
        "- The next layer flattens the data from 2D 28x28 to 1D 784. This layer is known as the input layer.\n",
        "- The next two (Dense) layers are hidden layers with 300 and 100 neurons respectively. They're both using sigmoid for their activation functions and contain a weight matrix that changes during training.\n",
        "- The last dense layer is the output layer. Choosing 10 neurons is a reflection of our output. We use a sigmoid function in order to calculate the probability.\n",
        "\n",
        "This is, again, a 2-layered neural network. Let's print out the summary of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T09:44:51.642758Z",
          "start_time": "2020-11-05T09:44:51.633595Z"
        },
        "id": "vT-idNmwpfS0"
      },
      "source": [
        "#Inputting the first hidden layer, should be in the shape of 0-1\n",
        "weight = model.layers[1].get_weights()\n",
        "weight[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etvCkQlbpfS7"
      },
      "source": [
        "We mentioned weights, that each layer contains it's own weights. As a reminder, a weight is needed to put emphasis on a feature in order to help a model model.\n",
        "\n",
        "We'll now be compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:08:08.021494Z",
          "start_time": "2020-11-05T10:08:07.961694Z"
        },
        "scrolled": true,
        "id": "cPwpVg9ypfS-"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", #Loss function\n",
        "              optimizer=\"sgd\", #Stochastic Gradient Descent\n",
        "             metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB1mJAWdpfTE"
      },
      "source": [
        "Let's train and evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:05:52.598975Z",
          "start_time": "2020-11-05T10:05:52.593859Z"
        },
        "id": "hicKsLb1pfTH"
      },
      "source": [
        "y_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:06:10.733470Z",
          "start_time": "2020-11-05T10:06:10.727824Z"
        },
        "id": "QutjAt37pfTN"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:06:19.243856Z",
          "start_time": "2020-11-05T10:06:19.238042Z"
        },
        "id": "HS5ic6yFpfTS"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:06:23.517784Z",
          "start_time": "2020-11-05T10:06:23.511968Z"
        },
        "id": "Tw2Vu0skpfTY"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:13:33.811067Z",
          "start_time": "2020-11-05T10:08:10.202691Z"
        },
        "code_folding": [],
        "id": "XiB2NUGQpfTc"
      },
      "source": [
        "#May take a while\n",
        "history = model.fit(X_train, y_train, epochs=30, \n",
        "                  validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbz_o4mwpfTi"
      },
      "source": [
        "Plotting the accuracy and loss of our training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:35:30.633481Z",
          "start_time": "2020-11-05T10:35:30.341672Z"
        },
        "id": "L1E4o0H0pfTj"
      },
      "source": [
        "#Plotting Accuracy\n",
        "plt.figure(figsize = (20, 7))\n",
        "plt.plot(np.arange(1, 31), history.history[\"accuracy\"], label = \"Train Data\")\n",
        "plt.plot(np.arange(1, 31), history.history[\"val_accuracy\"], label = \"Test Data\")\n",
        "plt.legend(fontsize = 15)\n",
        "plt.xlabel(\"Epoch\", size = 15)\n",
        "plt.ylabel(\"Accuracy\", size = 15)\n",
        "plt.title(\"Accuracy of MNIST over Epochs\", size = 20)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:36:14.197532Z",
          "start_time": "2020-11-05T10:36:13.905882Z"
        },
        "id": "zNDAwWeapfTn"
      },
      "source": [
        "#Plotting Loss\n",
        "plt.figure(figsize = (20, 7))\n",
        "plt.plot(np.arange(1, 31), history.history[\"loss\"], label = \"Train Data\")\n",
        "plt.plot(np.arange(1, 31), history.history[\"val_loss\"], label = \"Test Data\")\n",
        "plt.legend(fontsize = 15)\n",
        "plt.xlabel(\"Epoch\", size = 15)\n",
        "plt.ylabel(\"Loss\", size = 15)\n",
        "plt.title(\"Loss of MNIST over Epochs\", size = 20)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqJRUvDUpfTt"
      },
      "source": [
        "Since our training and validation data seems to be closely tied, we can conclude there's hardly any overfitting. Creating a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:37:35.043428Z",
          "start_time": "2020-11-05T10:37:32.637472Z"
        },
        "id": "4dU7OsjtpfTu"
      },
      "source": [
        "#Determining error from confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, np.argmax(model.predict(X_test), axis = -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AofGLLopfTz"
      },
      "source": [
        "A nicer plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T10:37:36.611674Z",
          "start_time": "2020-11-05T10:37:35.047048Z"
        },
        "id": "zhY8dwUdpfT0"
      },
      "source": [
        "#Creating a plotting function for a confusion matrix\n",
        "import itertools\n",
        "cm = confusion_matrix(y_test, np.argmax(model.predict(X_test), axis = -1))\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cm, plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "plt.title(\"Confusion Matrix For Model vs True Labels\", size = 20)\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], fmt),\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.xlabel(\"Predicted Labels\", size = 15)\n",
        "plt.xticks(np.arange(0, 10))\n",
        "plt.ylabel(\"True Labels\", size = 15)\n",
        "plt.yticks(np.arange(0, 10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gk0SwV6pfT5"
      },
      "source": [
        "A confusion matrix is useful in looking at what values are predicting expected values. For example, the graph above shows that our model predicted nine +30 times when in reality it was four. This checks out, as fours and nines can occasionally look alike.\n",
        "\n",
        "A note on reading a confusion matrix: The heavy blue diagonal represents correctly predicted labels. Everything outside the diagonal represents predicted labels that were wrong to guess a certain true label. Match the x-axis and y-axis to determine what values were guessed correctly/incorrectly. What's the highest incorrectly predicted number? Does it make sense why a model would confuse it (i.e. can the incorrectly predicted value and true label be similarly drawn)? Would a human confuse this incorrectly predicted number?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSuvAeUgC4bK"
      },
      "source": [
        "Finally, we see how our model performs using our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwq57XBdC2gH"
      },
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"loss:\", score[0], \"acc:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqf6-eCmpfT7"
      },
      "source": [
        "## Question 1: Your Turn, Get Better Results Than Me On MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tWEo6nZpfT7"
      },
      "source": [
        "Can you get better accuracy than me? I know there's specific hyperparameters where accuracy can get +99%. Here's a list of some hyperparameters you can tune:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCESB_YVpfT9"
      },
      "source": [
        "#### Hyperparameters:\n",
        "- Number of layers\n",
        "- Number of neurons in layers\n",
        "- Activation functions\n",
        "- Learning rate\n",
        "- Loss\n",
        "- Optimizer\n",
        "- Metrics\n",
        "- Epochs\n",
        "\n",
        "Hyperparameter testing shows how expensive testing every single option can be. I recommend changing the learning rate, number of layers, number of neurons, and activation function, but feel free to change or add whatever you'd like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNPSGv5ppfT9"
      },
      "source": [
        "#### Cheatsheet on how to do the above:\n",
        "- **Adding a layer**: `model.add(keras.layers.Dense())`\n",
        "- **Number of neurons in layers**: Input/change number inside `keras.layers.Dense()`\n",
        "- **Changing Activation functions**: In a dense layer, write `Dense(activation=\"InsertFunctionNameHere\")`. Examples of other functions can be found [here](https://keras.io/api/layers/activations/)\n",
        "- **Changing learning rate**: Involves importing `backend`. Instructions/a quick example can be found [here](https://stackoverflow.com/a/62113860).\n",
        "- **Changing Loss functions**: Same as changing Activation functions, but the loss is defined/changed when you call `model.compile(loss=\"InsertFunctionNameHere\")`. Be mindful to see what losses are appropriate for what models (you don't want a continuous loss on a binary model; continous and discrete don't mix!). This shouldn't be tweaked too much, but I want to give you all full control. List of loss functions [here](https://keras.io/api/losses/).\n",
        "- **Changing Optimizer**: This can speed up or give you better results:  `model.compile(optimizer=\"InsertOptimizerNameHere\")`. List of Optimizers are [here](https://keras.io/api/optimizers/). Try Adam or RMSprop since they seem to be popular.\n",
        "- **Changing or Adding Metrics**: Similar to changing optimizer and loss: `model.compile(metrics=[\"InsertListOfMetricsHere\"])`. You can run multiple metrics at the same time and it shouldn't decrease your performance. The same advise goes here as to changing loss functions: be aware what metrics are telling you what before you go on and change them. Here's a [list](https://keras.io/api/metrics/) of metrics.\n",
        "- **Changing Number of Epochs**: Changed when running `model.fit(epochs=\"InsertNumericValueHere\")`. Strategies of running a certain number of epochs can be found [here](https://www.codespeedy.com/how-to-choose-number-of-epochs-to-train-a-neural-network-in-keras/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mexfaLpzpfT-"
      },
      "source": [
        "Another way to improve results is to do image processing on the data. Since this notebook is to practice Keras I won't give any hints. But I do want to point it out since in real life, modifying data is universal to improving and speeding any model. You're more likely to do this first as a strategy than tweak for model parameters. For now, however, we do this for practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MSqehRA5rme"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "#If the two lines above give you error, mute them and run the following:\n",
        "# import tensorflow\n",
        "# tensorflow.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqq9EPjOpfT_"
      },
      "source": [
        "#TODO: Create model, compile, and train (and I highly recommend that you\n",
        "#plot/make a confusion matrix, as it's super helpful in gaining context to \n",
        "#how your model is acting and where is error largest.)\n",
        "###YOUR CODE BELOW###\n",
        "your_model = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQCz2WLjpfUE"
      },
      "source": [
        "###EXTRA CELL IF NEEDED###\n",
        "#Feel free to create as many as needed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toVbfan1DJEx"
      },
      "source": [
        "#Tester cell to see if your model is beating my results\n",
        "#Run this for your credit\n",
        "# your_score = your_model.evaluate(X_test, y_test)\n",
        "# print(\"loss:\", your_score[0], \"acc:\", your_score[1])\n",
        "# assert your_score[1] > score[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh6keY-bpfUH"
      },
      "source": [
        "## Question 2: Create a Fashion Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0wY_nrgpfUI"
      },
      "source": [
        "MNIST is known as being \"too easy\" for machine learning models. Classical ML models (e.g. SVMs, Random Forests) are able to score +99% accuracy with less training. Another similar dataset, named *Fashion MNIST*, is gaining popularity as it's a much harder classification problem while quite similar to MNIST.\n",
        "\n",
        "In this section, you will be creating a classifier for this fashion dataset. This dataset is very similar to MNIST in structure, so there won't be much hand holding in this section. In theory, you can copy/paste everything in the previous section and change very little. I recommend typing everything out (particularly in the Keras section) as it gets you familiar with actually learning Keras.\n",
        "\n",
        "A note about Fashion MNIST: the dataset is heavily pre-processed. The data won't look pretty to us (it's pixalated and colorless), but to a computer it's simple enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHGJiYja5tNQ"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "#If the two lines above give you error, mute them and run the following:\n",
        "# import tensorflow\n",
        "# tensorflow.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FS_YPdPpfUJ"
      },
      "source": [
        "#Load Data\n",
        "#HINT: You can load Fashion MNIST from Keras the same way you do with MNIST.\n",
        "#You may have to do some digging on the internet in order to do this.\n",
        "#This exercise is to get you familiar with the Keras API\n",
        "\n",
        "\n",
        "#Your labels in y are numbers from 0-9. Each of those numbers corresponds to \n",
        "#an index to a label in the labels variable. i.e. 8 = \"Bag\", 4 = \"Coat\", etc.\n",
        "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \n",
        "         \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T11:33:22.953917Z",
          "start_time": "2020-11-05T11:33:22.942629Z"
        },
        "id": "PNLkSCnspfUQ"
      },
      "source": [
        "#Analyze Data (Optional, up to you on what to discover). Recommend you take \n",
        "#plotImage to see how the data has been pre-processed initially. (In general, \n",
        "#it's always a good idea to know how your data looks like.) You may have to \n",
        "#modify plotImage.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgLyAUG3pfUa"
      },
      "source": [
        "#Pre-Process Data \n",
        "#Hint: Very similar to MNIST\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-05T11:34:53.648826Z",
          "start_time": "2020-11-05T11:34:53.637239Z"
        },
        "id": "Xc9FHwFzpfUf"
      },
      "source": [
        "#Create model\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "#If the two lines above give you error, mute them and run the following:\n",
        "# import tensorflow\n",
        "# tensorflow.random.set_seed(42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwTEEG8OpfUm"
      },
      "source": [
        "#Plots (Optional)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DVt4pdopfUr"
      },
      "source": [
        "#Tester cell to see if your model is beating my results\n",
        "# score = model.evaluate(X_test, y_test)\n",
        "# print(\"loss:\", score[0], \"acc:\", score[1])\n",
        "# assert 0.89 < score[1], \"Accuracy not high enough\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgfFHEkipfUw"
      },
      "source": [
        "Try to get above 89% accuracy for both train and test using various hyperparameters.\n",
        "\n",
        "What label is the most mislabeled (contains the most error) in this model? Plot a confusion matrix showing this. Does it make sense? Plot several datapoints using `plotImage` to find out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa7jY_B2pfUw"
      },
      "source": [
        "#Confusion Matrix\n",
        "# import itertools\n",
        "# cm = confusion_matrix(y_test, np.argmax(model.predict(X_test), axis = -1))\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# plt.imshow(cm, plt.cm.Blues)\n",
        "# plt.colorbar()\n",
        "# plt.title(\"Confusion Matrix For Model vs True Labels\", size = 20)\n",
        "# fmt = 'd'\n",
        "# thresh = cm.max() / 2.\n",
        "# for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "#     plt.text(j, i, format(cm[i, j], fmt),\n",
        "#               horizontalalignment=\"center\",\n",
        "#               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "# plt.xlabel(\"Predicted Labels\", size = 15)\n",
        "# plt.xticks(np.arange(0, 10), labels=labels, rotation = 45)\n",
        "# plt.ylabel(\"True Labels\", size = 15)\n",
        "# plt.yticks(np.arange(0, 10), labels=labels)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etcq-lGqpfU0"
      },
      "source": [
        "## Question 3: Bonus - EMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qhzfZO2pfU0"
      },
      "source": [
        "EMNIST is an expansion of MNIST on [Kaggle](https://www.kaggle.com/crawford/emnist). If you feel you still need some practice, feel free to check it out. Others have made notebooks on Kaggle with other fancy techniques. Explore if you have time!\n",
        "\n",
        "If you're interested in similar preprocessed datasets, check out this website: https://analyticsindiamag.com/fashion-and-medical-mnist/. They link to medical datasets and a sign language-like MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww13vYIIURGV"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Once you're ready to submit, turn in a copy of this Jupyter notebook and a PDF copy of it. For the PDF, please label the pages of questions 1, 2, and (optionally) 3.\n",
        "\n",
        "Locally, there should a \"Download as\" under \"File\" and PDF should be an option. \n",
        "\n",
        "If you're doing this assignment using Colab, Colab does not have this PDF option. I recommend openning this notebook using IPython/Jupyter Notebook locally and doing the instruction above. If you're resistant to this option, there are other options. If you're on a Mac, a hack you can do is to print this page and before you print, save the file as a PDF instead of printing. \n",
        "\n",
        "An alternative is to save your Colab notebook as an HTML file and convert that into a PDF (using a third party website like https://html2pdf.com/ or a browser extension like https://chrome.google.com/webstore/detail/web-page-to-pdf-converter/bbfoccanbdeldjaelafmbgonagegdndg). Converting HTMLs into PDFs tends to be easier/more common than ipynb to PDFs. If you need additional help, please feel free to Slack Kevin or Jess for aid!"
      ]
    }
  ]
}